{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28098c6b-de8c-49e7-95ac-4e52f414e292",
   "metadata": {},
   "source": [
    "# Topic Modeling: Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9708b0-f7f6-47f8-8319-8824ef1f2f89",
   "metadata": {},
   "source": [
    "## 1. **What is NMF?** \n",
    "[Source: Wikipedia](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)\n",
    "\n",
    "**Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation** is a group of algorithms in multivariate analysis and linear algebra where **a matrix $\\large{\\textbf{V}}$ is factorized into (usually) two matrices $\\large{\\textbf{W}}$ and $\\large{\\textbf{H}}$, with the property that all three matrices have no negative elements.**\n",
    "\n",
    "\n",
    "Let matrix $\\large{\\textbf{V}}$ be the product of matrics $\\large{\\textbf{W}}$ and $\\large{\\textbf{H}}$,\n",
    "$$\\large{\\textbf{V} = \\textbf{WH}}$$\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/nmf_2.png\" width=500/>\n",
    "</div>\n",
    "\n",
    "### Assumption\n",
    "When multiplying matrices, **the dimensions of the factor matrices may be significantly lower than those of the product matrix and it is this property that forms the basis of NMF.** NMF generates factors with significantly reduced dimensions compared to the original matrix. For example, if $\\large{\\textbf{V}}$ is an $m \\times n$ matrix, $\\large{\\textbf{W}}$ is an $m \\times p$ matrix, and $\\large{\\textbf{H}}$ is a $p \\times n$ matrix then $p$ can be significantly less than both $m$ and $n$.\n",
    "$$p << m \\text{ and } p << n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627b8b7-c3a1-4d23-8e4a-6ff5d8d8bcd6",
   "metadata": {},
   "source": [
    "## NMF: Example(Topic-Modelling)\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/nmf_1.png\" width=600/>\n",
    "</div>\n",
    "\n",
    "- **Here is an example:**\n",
    "\n",
    "    - Let the input matrix (the matrix to be factored) be $\\textbf{V}$ with 10000 rows and 500 columns where words are in rows and documents are in columns. That is, we have 500 documents indexed by 10000 words. It follows that a column vector $\\textbf{v}$ in $\\textbf{V}$ represents a document.\n",
    "\n",
    "    - Assume we ask the algorithm to find 10 features in order to generate a features matrix $\\textbf{W}$ with 10000 rows and 10 columns and a coefficients matrix $\\textbf{H}$ with 10 rows and 500 columns.\n",
    "\n",
    "    - The product of $\\textbf{W}$ and $\\textbf{H}$ is a matrix with 10000 rows and 500 columns, the same shape as the input matrix V and, if the factorization worked, it is a reasonable approximation to the input matrix $\\textbf{V}$.\n",
    "\n",
    "    - From the treatment of matrix multiplication above it follows that each column in the product matrix $\\textbf{WH}$ is a linear combination of the 10 column vectors in the features matrix $\\textbf{W}$ with coefficients supplied by the coefficients matrix $\\textbf{H}$.\n",
    "\n",
    "This last point is the basis of NMF because we can consider each original document in our example as being built from a small set of hidden features. NMF generates these features.\n",
    "\n",
    "- It is useful to think of each feature (column vector) in the features matrix W as a document archetype comprising a set of words where each word's cell value defines the word's rank in the feature: The higher a word's cell value the higher the word's rank in the feature. \n",
    "    - Each topic(column-vector) in matrix $\\textbf{W}$ is a collection of words.<br></br>\n",
    "\n",
    "- A column in the coefficients matrix $\\textbf{H}$ represents an original document with a cell value defining the document's rank for a feature. \n",
    "\n",
    "- We can now reconstruct a document (column vector) from our input matrix $\\textbf{V}$ by a linear combination of our features (column vectors in $\\textbf{W}$) where each feature is weighted by the feature's cell value from the document's column in $\\textbf{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e750b-c4ad-4cec-90cf-1aad5b645b69",
   "metadata": {},
   "source": [
    "## Approximate non-negative matrix factorization\n",
    "\n",
    "Usually the number of columns of $\\large{\\textbf{W}}$ and the number of rows of $\\large{\\textbf{H}}$ in NMF are selected so the product $\\large{\\textbf{WH}}$ will become an approximation to $\\large{\\textbf{V}}$. \n",
    "\n",
    "The full decomposition of $\\large{\\textbf{V}}$ then amounts to the two non-negative matrices $\\large{\\textbf{W}}$ and $\\large{\\textbf{H}}$ as well as a residual $\\large{\\textbf{U}}$, such that: $\\large{\\textbf{V = WH + U}}$. The elements of the residual matrix can either be negative or positive.\n",
    "\n",
    "When $\\large{\\textbf{W}}$ and $\\large{\\textbf{H}}$ are smaller than $\\large{\\textbf{V}}$ they become easier to store and manipulate. \n",
    "\n",
    "**Another reason for factorizing $\\large{\\textbf{V}}$ into smaller matrices $\\large{\\textbf{W}}$ and $\\large{\\textbf{H}}$, is that if one is able to approximately represent the elements of $\\large{\\textbf{V}}$ by significantly less data, then one has to infer some latent structure in the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a5b16-a09f-4894-96e1-b7d3a8b462cf",
   "metadata": {},
   "source": [
    "Extra Resources:\n",
    "-  https://medium.com/voice-tech-podcast/topic-modelling-using-nmf-2f510d962b6e\n",
    "- https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
